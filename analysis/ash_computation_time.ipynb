{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling adaptive shrinkage computations with mix-SQP and IP solvers\n",
    "\n",
    "An initial motivation for this work was our interest in applying a nonparametric Empirical Bayes method, “adaptive shrinkage,” to very large data sets. These Empirical Bayes computations involve three steps: \n",
    "\n",
    "1. likelihood computation,\n",
    "2. maximum-likelihood estimation of the mixture proportions, and\n",
    "3. posterior computation.\n",
    "\n",
    "Here we profile the runtime of each of these steps, in which the second step (maximum-likelihood estimation) is solved using either an interior point method (`MOSEK`) or the SQP algorithm we have developed. Our initial solution used the commercial interior point solver MOSEK (called via the `KWDual` function in the `REBayes` R package), and here we show that the mix-SQP solver yields a large improvement in performance, to the point that the model fitting step is no longer the predominant computational effort.\n",
    "\n",
    "The adaptive shrinkage calculations from the [ashr package](https://github.com/stephens999/ashr) are reproduced here in Julia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis setup\n",
    "\n",
    "*Before attempting to run this Julia code, make sure your computer is properly set up to run this code by following the setup instructions in the README of the [git repository](https://github.com/stephenslab/mixsqp-paper).*\n",
    "\n",
    "We begin by loading the Distributions, LowRankApprox and RCall Julia packages, as well as some function definitions used in the code chunks below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Distributions\n",
    "using LowRankApprox\n",
    "using RCall\n",
    "include(\"../code/datasim.jl\");\n",
    "include(\"../code/likelihood.jl\");\n",
    "include(\"../code/mixSQP.jl\");\n",
    "include(\"../code/REBayes.jl\");\n",
    "include(\"../code/ash.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, initialize the sequence of pseudorandom numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "srand(1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a small data set\n",
    "\n",
    "Let's begin with a smaller example with 50,000 samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = round(Int,5e4);\n",
    "z = normtmixdatasim(n);\n",
    "s = ones(n);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the standard errors (`s`) of the provided estimates (`z`) are assumed to be all 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Run adaptive shrinkage\n",
    "\n",
    "Run the adaptive shrinkage method with model fitting implemented using the mix-SQP (`method = \"mixSQP\"`) and MOSEK (`method = \"REBayes\"`) algorithms. This is a trial run intended to first precompile the relevant functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gridmult    = 1.2;\n",
    "out_rebayes = ash(z,s,gridmult = gridmult,method = \"REBayes\");\n",
    "out_mixsqp  = ash(z,s,gridmult = gridmult,method = \"mixSQP\",lowrank = \"qr\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we re-run the adaptive shrinkage computations, this time recording the runtimes for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_rebayes = ash(z,s,gridmult = gridmult,method = \"REBayes\");\n",
    "out_mixsqp  = ash(z,s,gridmult = gridmult,method = \"mixSQP\",lowrank = \"qr\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's summarize the computational effort of adaptive shrinkage in this example data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " solver likelihood fitting posterior\n",
      "  MOSEK      0.132   1.827     0.097\n",
      "mix-SQP      0.098   0.335     0.012\n"
     ]
    }
   ],
   "source": [
    "@printf \" solver likelihood fitting posterior\\n\"\n",
    "@printf(\"  MOSEK %10.3f %7.3f %9.3f\\n\",out_rebayes[\"timing-likelihood\"],\n",
    "        out_rebayes[\"timing-fit\"],out_rebayes[\"timing-posterior\"])\n",
    "@printf(\"mix-SQP %10.3f %7.3f %9.3f\\n\",out_mixsqp[\"timing-likelihood\"],\n",
    "        out_mixsqp[\"timing-fit\"],out_mixsqp[\"timing-posterior\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The likelihood and posterior computations are roughly the same with both optimization algorithms, which is expected because these steps are unchanged.\n",
    "\n",
    "As for the model fitting step, we observe it is the slowest step in both cases. Still, the SQP approach is substantially faster than the interior point method (MOSEK), to the point that the model fitting step is comparable in runtime to the likelihood computation step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance on a larger data set\n",
    "\n",
    "Next, let's profile the same adaptive shrinkage computations in a larger data set with more samples, and with a finer-scale grid of normal densities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = round(Int,1e5)\n",
    "z = normtmixdatasim(n);\n",
    "s = ones(n);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run adaptive shrinkage using mix-SQP (`method = \"mixSQP\"`) and MOSEK (`method = \"REBayes\"`) in the model-fitting step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gridmult    = 1.05;\n",
    "out_rebayes = ash(z,s,gridmult = gridmult,method = \"REBayes\");\n",
    "out_mixsqp  = ash(z,s,gridmult = gridmult,method = \"mixSQP\",lowrank = \"qr\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, summarize the computational effort of adaptive shrinkage on the larger data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " solver likelihood fitting posterior\n",
      "  MOSEK      1.057  17.191     0.160\n",
      "mix-SQP      0.983   0.769     0.040\n"
     ]
    }
   ],
   "source": [
    "@printf \" solver likelihood fitting posterior\\n\"\n",
    "@printf(\"  MOSEK %10.3f %7.3f %9.3f\\n\",out_rebayes[\"timing-likelihood\"],\n",
    "        out_rebayes[\"timing-fit\"],out_rebayes[\"timing-posterior\"])\n",
    "@printf(\"mix-SQP %10.3f %7.3f %9.3f\\n\",out_mixsqp[\"timing-likelihood\"],\n",
    "        out_mixsqp[\"timing-fit\"],out_mixsqp[\"timing-posterior\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is similar to above, but more dramatic—the effort of model fitting with mix-SQP is comparable to the effort required to compute the likelihood matrix, whereas the model fitting using the interior point method (MOSEK) dominates the effort of the other steps. \n",
    "\n",
    "In summary, this illustrates the benefit of the SQP approach for adaptive shrinkage, particularly for large data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session information\n",
    "\n",
    "The section gives information about the computing environment used to generate the results contained in this\n",
    "notebook, including the version of Julia and the Julia packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Distributions                 0.15.0\n",
      " - LowRankApprox                 0.1.1\n",
      " - RCall                         0.10.2\n",
      "Julia Version 0.6.2\n",
      "Commit d386e40c17 (2017-12-13 18:08 UTC)\n",
      "Platform Info:\n",
      "  OS: macOS (x86_64-apple-darwin14.5.0)\n",
      "  CPU: Intel(R) Core(TM) i7-7567U CPU @ 3.50GHz\n",
      "  WORD_SIZE: 64\n",
      "  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Prescott)\n",
      "  LAPACK: libopenblas64_\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-3.9.1 (ORCJIT, broadwell)\n"
     ]
    }
   ],
   "source": [
    "Pkg.status(\"Distributions\")\n",
    "Pkg.status(\"LowRankApprox\")\n",
    "Pkg.status(\"RCall\")\n",
    "versioninfo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
